\documentclass{article}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage{etoolbox}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}


	
\pagestyle{fancy}
\title{Chapter 11}
\author{Michelle Bodnar, Andrew Lohr}

\newcounter{curnum}
\setcounter{curnum}{0}

\newtheorem{th1}{Exercise}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calY}{\mathcal{Y}}

\begin{document}
\maketitle

\noindent\textbf{ Exercise 11.1-1} \\

Starting from the first index in $T$, keep track of the highest index so far that has a non NIL entry. This takes time $O(m)$.\\


\noindent\textbf{ Exercise 11.1-3} \\
You could have each entry in the table be either a pointer to a doubly linked list containing all the objects with that key, or NIL if there are none. search just returns the first element in the list corresponding to the given key. Since all the elements in the list have that same key, it doesn't matter which search returns. Insert just adds to the start of teh doubly linked list. Finally, deletion can be done in constant time in a doubly linked list, see problem 10-1\\


\noindent\textbf{ Exercise 11.2-1} \\
Under the assumption of simple uniform hashing, we will use linearity of expectation to compute this. Suppose that all the keys are totally ordered $\{k_1,\ldots, k_{n}\}$. Let $X_i$ be the number of $\ell > k_i$ so that $h(\ell) = h(k_i)$. Note, that this is the same thing as $\sum_{j>i} Pr(h(k_j) = h(k_i)) = \sum_{j>i} 1/m = (n-i)/m$. Then, by linearity of expectation, the number of collisions is the sum of the number of collisions for each possible smallest element in the collision. The expected number of collisions is $\sum_{i=1}^n \frac{n-i}{m} = \frac{n^2  - \frac{n(n+1)}{2}}{m} = \frac{n^2 -n}{2m}$\\

\noindent\textbf{ Exercise 11.2-3} \\
Both kinds of searches become expected runtime of $\Theta(1+ \lg(\alpha))$. Insertions and deletions stay $\Theta(1+ \alpha)$ because the time to insert into or delete from a sorted list is linear. \\

\noindent\textbf{ Exercise 11.2-5} \\
There is a subset of size n hashing to the same spot, because if each spot only had $n-1$ elements hashing to it, then the universe could only be size $(n-1)m$. The worst case searching time would be if all of the elements that we put in the hashtable were this subset of size n all going to the same spot, which is linear. \\


\noindent\textbf{ Exercise 11.3-1} \\
If every element also contained a hash of the long character string, when we are searching for the desired element, we'll first check if the hashvalue of the node in the linked list, and move on if it disagrees. This can increase the runtime by a factor proportional to the length of the long character strings.\\


\noindent\textbf{ Exercise 11.3-3} \\
We will show that each string hashes to the sum of it's digits mod $2^p-1$. We will do this by induction on the length of the string. As a base case, suppose the string is a single character, then the value of that character is the value of $k$ which is then taken mod $m$. Now, for an inductive step, let $w = w_1 w_2$ where $|w_1|\ge 1$ and $|w_2|=1$. Suppose, $h(w_1) = k_1$. Then, $h(w) = h(w_1)2^p + h(w_2) \mod 2^p-1 = h(w_1)+h(w_2) \mod 2^p-1$. So, since $h(w_1)$ was the sum of all but the last digit mod $m$, and we are adding the last digit mod $m$, we have the desired conclusion.\\

\noindent\textbf{ Exercise 11.3-5} \\
%Suppose to a contradiction that we had an $\epsilon < \frac{1}{|B|} - \frac{1}{|U|}$ so that for every pair $k$ and $\ell$ in the universe, $Pr\{h(k) = h(l) \} \le \epsilon$.

\noindent\textbf{ Exercise 11.4-1} \\
This is what the array will look like after each insertion when using linear probing:
$
\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
&&&&&&&&&&10\\
\hline
22&&&&&&&&&&10\\
\hline
22&&&&&&&&&31&10\\
\hline
22&&&&4&&&&&31&10\\
\hline
22&&&&4&15&&&&31&10\\
\hline
22&&&&4&15&28&&&31&10\\
\hline
22&&&&4&15&28&17&&31&10\\
\hline
22&88&&&4&15&28&17&&31&10\\
\hline
22&88&&&4&15&28&17&59&31&10\\
\hline
\end{array}
$

For quadradic probing, it will look identical until there is a collision on inserting the fifth element. Then, it is

$
\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
22&&&&4&&&&15&31&10\\
\hline
22&&&&4&&28&&15&31&10\\
\hline
22&&&17&4&&28&&15&31&10\\
\hline
22&&88&17&4&&28&&15&31&10\\
\hline
22&&88&17&4&&28&&15&31&10\\
\hline
\end{array}
$ 

Note that there is no way to insert the element 59 now, because the offsets coming from $c_1 =1$ and $c_2 =3$ can only be even, and an odd offest would be required to insert 59 because $59 \mod 11 = 4$ and all the empty positions are at odd indices.

For double hashing, it is the same as linear probing. \\

\noindent\textbf{ Exercise 11.4-3} \\
For the $\alpha = 3/4$ case, we just plug into theorems 11.6 and 11.8 respectively to get that for a unsuccessfull search, the expected number of probes is bounded by $4$. And for a sucessfull search, the expected number of probes is bounded by $\frac{4}{3}\ln(4)$.

For $\alpha = 7/8$. The bound for expected number of probes of unsucessfull is $8$, and for sucessfull is $\frac{8}{7}\ln(8)$.\\

\noindent\textbf{ Exercise 11.4-5} \\
We will try to find a rational solution, let $\alpha = m/n$. Using theorems 11.6 and 11.8, we have to solve the equation 
\[
\frac{1}{1-\alpha} = \frac{2}{\alpha}\ln(\frac{1}{1-\alpha}) 
\]

Unfortunately, this trancendental equation cannot be solved using simple techniques. There is an exact solution using the Lambert W function of 
\[
\frac{1}{2}\frac{1+2LambertW(-1, -(\frac{1}{2})*exp(-\frac{1}{2}))}{LambertW(-1, -(\frac{1}{2})*exp(-\frac{1}{2})) }
\]

Which evaluates to approximately $\alpha = .7153$.\\

\noindent\textbf{ Exercise 11.5-1} \\
%There are $\binom{n}{2}$ pairs of elements, each colliding with probability $\frac{1}{m}$. So, the probability that that pair does not collide is $\frac{m-1}{m}$. So, by the union bound, none of these pairs collide with probability $\binom{n}{2} \frac{m-1}{m}$.\\

Let $A_{j,k}$ be the event that $j$ and $k$ hash to different things. Due to uniform hashing, $Pr(A_{j,k})  = \frac{m-1}{m}$. Also, we can say that there is a negative correlation between the events. That is, if we know that several pairs of elements hashed to the same thing, then we can only decrease the likelyhood that some other pair hashed to different things. This gets us that the probability that all events happen is $\le$ the probability that the all happened if they were independent, so,
\[
Pr(\cap_{j,k} A_{j,k}) \le \left(\frac{m-1}{m}\right)^{\binom{n}{2}} \le \left( e^{-1/m}\right)^{\frac{n(n-1)}{2}} = e^{\frac{-n(n-1)}{2m}}
\]

So, if we have that that $n$ exceeds $m$, the $-n^2/(2m)$ term is much bigger than the $n/2m$ term, so, the exponent is going to $-\infty$, which means the probability is going to 0. 

\noindent\textbf{ Problem 11-1} \\
\begin{enumerate}[a.]
\item
The index for each probe is computed uniformly from among all the possible indices. Since we have $n\le m/2$, we know that there are at least half of the indices empty at any stage. So, for more than $k$ probes to be required, we would need that in each of $k$ first probes, we probed a vertex that already had an entry, this has probability less than $1/2$, so the probability of it happening each time is $< 1/(2^k)$.

\item
Using the result from the previous part with $k= 2\lg(n)$, we have that the probability that so many probes will be required is \[< 2^{-2\lg(n)} = 2^{\lg( n^{-2})} = n^{-2} = \frac{1}{n^2}\]

\item
We apply a union bound followed by the results of the previous part
\[
Pr\{X > 2\lg(n)\} = Pr\{ \vee_i X_i >2\lg(n)\} \le \sum_i Pr\{X_i > 2\lg(n)\} \le \sum_{i} \frac{1}{n^2} = \frac{n}{n^2} = \frac{1}{n}
\]

\item
The longest possible length of a probe sequence is $n$, as we would try checking every single entry already placed in the array. We also know that the probability that a sequence of length more than $2\lg(n)$ is required is $\le 1/n$. So, we have that the largest the expected value can be is 
\[
E[X] \le Pr\{X \le 2\lg(n)\} 2\lg(n) + Pr\{ X >\lg(n)\} n =  \frac{n-1}{n} 2\lg(n) + \frac{1}{n}n = 2\lg(n) + 1 - 2\frac{\lg(n)}{n} \in O(\lg(n))
\]

\end{enumerate}



\noindent\textbf{ Problem 11-3} \\
\begin{enumerate}[a.]
\item
At each step, we are increasing the amount we increase by by 1, so, this leads to the ``Gauss numbers'' which have formula $\frac{i^2+i}{2}$. So, we have $c_1 = c_2 = \frac{1}{2}$.

\item

To show that this algorithm examines every number, we will show that every number that it examines is distinct. Then, since it examines $m$ numbers total, this will imply that every number is visited. Suppose that we visited the same position on rounds $i$ and $i'$, then,
\[
h(k) + \frac{i+i^2}{2} \equiv h(k) + \frac{i'+i'^2}{2} \mod m
\]
Which means
\[
 \frac{i+i^2}{2} \equiv\frac{i'+i'^2}{2} \mod m
\]
So,
\[
 i+i^2 \equiv i'+i'^2 \mod 2m
\]
Rearranging,
\[
 i - i' \equiv i^2 - i'^2 = (i+i')(i-i') \mod 2m
\]
Which would mean,
\[
1 \equiv(i+i') \mod 2m
\]
However, there are only $m$ rounds, so, we have that
\[
1 = i+i'
\]
Which is not possible because this would only corrsepond to having the first ($i=0$) and second($i=1$) rounds be probing the same position. This could only happen if $m=1$. and if $m=1$, then we wouldn't even have the second round occur. So, we have our contradiction and so every probe was to a distinct position, meaning every position was probed.
\item

\end{enumerate}



\end{document} 