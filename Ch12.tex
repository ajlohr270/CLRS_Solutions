\documentclass{article}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage{etoolbox}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}


	
\pagestyle{fancy}
\title{Chapter 12}
\author{Michelle Bodnar, Andrew Lohr}

\newcounter{curnum}
\setcounter{curnum}{0}

\newtheorem{th1}{Exercise}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calY}{\mathcal{Y}}

\begin{document}
\maketitle

\noindent\textbf{ Exercise 12.1-1} \\
Anytime that a node has a single child, treat it as the right child, with the left child being NIL

\begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
\node [circle,draw] (z){10}
  child {node [circle,draw] (a) {4}
    child {node [circle,draw] (b) {1}
      }
    child {node [circle,draw] (g) {5}
  }
  }
  child {node [circle,draw] (a) {17}
    child {node [circle,draw] (b) {16}
	}
    child {node [circle,draw] (g) {21}
  }
        };
\end{tikzpicture}

\begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
\node [circle,draw] (z){10}
  child {node [circle,draw] (a) {4}
    child {node [circle,draw] (b) {1}
      }
    child {node [circle,draw] (g) {5}
  }
  }
  child {node [circle,draw] (a) {16}
    child {node [circle,draw] (b) {17}
    child {node [circle,draw] (g) {21}
  }}
        };
\end{tikzpicture}

\begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
\node [circle,draw] (z){5}
  child {node [circle,draw] (a) {1}
    child {node [circle,draw] (g) {4}
  }
  }
  child {node[circle,draw] (y) {10}
  child {node [circle,draw] (a) {16}
    child {node [circle,draw] (b) {17}
    child {node [circle,draw] (g) {21}
  }}}
        };
\end{tikzpicture}

\begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
\node [circle,draw] (z){4}
  child {node [circle,draw] (a) {1}
  }
   child {node[circle,draw] (x) {5}
  child {node[circle,draw] (y) {10}
  child {node [circle,draw] (t) {16}
    child {node [circle,draw] (b) {17}
    child {node [circle,draw] (g) {21}
  }}}} };
\end{tikzpicture}

\begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
\node [circle,draw] (z){1}
  child {node [circle,draw] (x) {4}
   child {node[circle,draw] (t) {5}
  child {node[circle,draw] (y) {10}
  child {node [circle,draw] (a) {16}
    child {node [circle,draw] (b) {17}
    child {node [circle,draw] (g) {21}
  }}}}}
        };
\end{tikzpicture}

\noindent\textbf{ Exercise 12.1-3} \\
Our solution to exercise 10.4-5 solves this problem.\\

\noindent\textbf{ Exercise 12.1-5} \\
Suppose to a contradiction that we could build a bst in worst case time $o(n\lg(n))$. Then, to sort, we would just construct the BST and then read off the elements in an inorder traversal. This second step can be done in time $\Theta(n)$ by Theorem 12.1. Also, an inorder traversal must be in sorted order because the elements in the left subtree are all those that are smaller than the current element, and they all get printed out before the current element, and the elements of the right subtree are all those elements that are larger and they get printed out  after the current element. This would allow us to sort in time $o(n\lg(n))$ a contradiction\\


\noindent\textbf{ Exercise 12.2-1} \\
option $c$ could not be the sequence of nodes explored because we take the left child from the 911 node, and yet somehow manage to get to the 912 node which cannot belong the left subtree of 911 because it is greater. Option $e$ is also impossible because we take the right subtree on the 347 node and yet later come across the 299 node.\\

\noindent\textbf{ Exercise 12.2-3} \\
\begin{algorithm}
\caption{TREE-PREDECESSOR(x)}
\begin{algorithmic}
\If{$x.left \neq NIL$}
\State \Return TREE-MAXIMUM(x.left)
\EndIf
\State $y = x.p$
\While{$y\neq NIL$ and $x==y.left$}
\State $x=y$
\State $y=  y.p$
\EndWhile
\State\Return $y$
\end{algorithmic}
\end{algorithm}

\noindent\textbf{ Exercise 12.2-5} \\
Suppose the node $x$ has two children. Then it's successor is the minimum element of the BST rooted at $x.right$. If it had a left child then it wouldn't be the minimum element. So, it must not have a left child. Similarly, the predecessor must be the maximum element of the left subtree, so cannot have a right child.\\

\noindent\textbf{ Exercise 12.2-7} \\
To show this bound on the runtime, we will show that using this procedure, we traverse each edge twice. This will suffice because the number of edges in a tree is one less than the number of vertices.

Consider a vertex of a BST, say $x$. Then, we have that the edge between $x.p$ and $x$ gets used when successor is called on $x.p$ and gets used again when it is called on the largest element in the subtree rooted at $x$. Since these are the only two times that that edge can be used, apart from the initial finding of tree minimum. We have that the runtime is $O(n)$. We trivially get the runtime is $\Omega(n)$ because that is the size of the output.\\

\noindent\textbf{ Exercise 12.2-9} \\
If $x = y.left$ then calling successor on $x$ will result in no iterations of the while loop, and so will return $y$. Similarly, if $x =y.right$, the while loop for calling predecessor(see exercise 3) will be run no times, and so $y$ will be returned. Then, it is just a matter of recognizing what the problem asks to show is exactly that y  is either predecessor(x) or successor(x).\\

\noindent\textbf{ Exercise 12.3-1} \\
The initial call to TREE-INSERT-REC should be NIL,T.root,z
\begin{algorithm}
\caption{TREE-INSERT-REC(y,x,z)}
\begin{algorithmic}
\If{$x \neq NIL$}
\If{$z.key < x.key$}
\State TREE-INSERT-REC(x,x.left,z)
\Else
\State TREE-INSERT-REC(x,x,right,z)
\EndIf
\EndIf
\State z.p = y
\If{$y==NIL$}
\State T.root = z
\ElsIf{$z.key <y.key$}
\State y.left = z
\Else
\State y.right = z
\EndIf
\end{algorithmic}
\end{algorithm}

\noindent\textbf{ Exercise 12.3-3} \\
The worst case is that the tree formed has height $n$ because we were inserting them in already sorted order. This will result in a runtime of $\Theta(n^2)$. In the best case, the tree formed is approximately balanced. This will mean that the height doesn't exceed $O(\lg(n))$. Note that it can't have a smaller height, because a complete binary tree of height $h$ only has $\Theta(2^h)$ elements. This will result in a rutime of $O(n\lg(n)$. We showed $\Omega(n\lg(n))$ in exercise 12.1-5.

\noindent\textbf{ Exercise 12.3-5} \\
Our insertion procedure follows closely our solution to 12.3-1, the difference being that once it finds the position to insert the given node, it updates the succ fields appropriately instead of the p field of z.

\begin{algorithm}
\caption{TREE-INSERT'(y,x,z)}
\begin{algorithmic}
\If{$x \neq NIL$}
\If{$z.key < x.key$}
\State TREE-INSERT'(x,x.left,z)
\Else
\State TREE-INSERT'(x,x,right,z)
\EndIf
\EndIf
\If{$y==NIL$}
\State T.root = y
\ElsIf{$z.key <y.key$}
\State y.left = z
\State x.succ = y
\Else
\State y.right = z
\State z.succ = y.succ
\State y.succ = z
\EndIf
\end{algorithmic}
\end{algorithm}

Our Search procedure is unchanged from the version given in the previous section

We will assume for the deletion procedure that all the keys are distinct, as that has been a frequent assumption throughout this chapter. This will however depend on it. Our deletion procedure first calls search until we are one step away from the node we are looking for, that is, it calls TREE-PRED(T.root,z.key)

\begin{algorithm}
\caption{TREE-PRED(x,k)}
\begin{algorithmic}
\If{$k<x.key$}
\State $y = x.left$
\Else
\State $y = x.right$
\EndIf
\If{$y == NIL$}
\State throw error
\ElsIf{$y.key = k$}
\State \Return x
\Else
\State \Return TREE-PRED(y,k)
\EndIf
\end{algorithmic}
\end{algorithm}

It can use this TREE-PRED procedure to comput $u.p$ and $v.p$ in the TRANSPLANT procedure. Since TREE-DELETE only calls TRANSPLANT a constant number of times, increasing the runtime of TRANSPLANT to $O(h)$ in this way causes the runtime of the new TREE-DELETE procedure to be $O(h)$.\\

\noindent\textbf{ Exercise 12.4-1} \\
Consider all the possible positions of the largest element of the subset of $n+3$ of size 4. Suppose it were in position $i+4$ for some $i\le n-1$. Then, we have that there are $i+3$ positions from which we can select the remaining three elements of the subset. Since every subset with different largest element is different, we get the total by just adding them all up (inclusion exclusion principle).\\


\noindent\textbf{ Exercise 12.4-3} \\
Suppose we have the elements $\{1,2,3\}$. Then, if we construct a tree by a random ordering, then, we get trees which appear with probabilities some multiple of $\frac{1}{6}$. However, if we consider all the valid binary search trees on the key set of $\{1,2,3\}$. Then, we will have only five different possibilities. So, each will occur with probability $\frac{1}{5}$, which is a different probability distribution.\\


\noindent\textbf{ Exercise 12.4-5} \\

Suppose that when quikcksort always selects it's elements to be in the middle $n^{1-k/2}$ of the elements each time. Then, the size of the problem shrinks by a power of at least $(1-k/2)$ each time. So, the greatest depth of recursion $d$ will be so that $n^{(1-k/2)^d} \le2$, solving for $d$, we get $(1-k/2)^d \le \log_n(2) = \lg(2)/\lg(n)$, so, $d \le \log_{1-k/2}(\lg(2)) - \log_{1-k/2}(\lg(n) = \log_{1-k/2}(\lg(2)) - \lg(\lg(n))/ \lg(1-k/2)$.

Let A(n) deonte the probabiltiy that when quicksorting a list of length $n$, some pivot is selected to not be in  the middle $n^{1-k/2}$ of the numbers. This doesn't happen with probability $\frac{1}{n^{k/2}}$. Then, we have that the two subproblems are of size$n_1,n_2$ with $n_1+n_2 = n-1$ and $\max\{n_1,n_2\} \le n^{1-k/2}$. So, $A(n) \le \frac{1}{n^{k/2}} + T(n_1)+T(n_2)$ So, since we bounded the depth by $O(1/\lg(n))$ let \{a_{i,j}\}_i be all the subproblem sizes left at depth $j$. So, A(n) \le \frac{1}{n^{k/2}}\sum_{j} \sum_i \frac{1}{a

\noindent\textbf{Problem 1} \\
\begin{enumerate}[a.]
\item
Each insertion will add the elemement to the right of the rightmost leaf because the inequality on line 11 will always evaluate to false. This will result in the runtime being $\sum_{i=1}^n i \in \Theta(n^2)$

\item
This strategy will result in each of the two children subtrees having a difference in size at most one. This means that the height will be $\Theta(\lg(n))$. So, the total runtime will be $\sum_{i=1}^n \lg(n) \in \Theta(n\lg(n))$

\item
This will only take linear time since the tree itself will be height 0, and a single insertion into a list can be done in constant time.

\item
The worst case performance is that every random choice is to the right (or all to the left) this will result in the same behavior as in the first part of this problem, $\Theta(n^2)$

To compute the expected runtime informally, just notice that when randomly choosing, we will pick left roughly half the time, so, the tree will be roughly balanced, so, we have that the depth is roughly $\lg(n)$, so the expected runtime will be $n\lg(n)$.


\end{enumerate}


\noindent\textbf{Problem 3} \\
\begin{enumerate}[a.]
\item
Since we are averaging over all nodes $x$ the value of $d(x,T)$, it is $\frac{1}{n} \sum_{x\in T} d(x,T)$, but by definition, this is $\frac{1}{n} P(T)$.

\item
Every non-root node has a contribution of one coming from the first edge from the root on its way to that node, every other edge in this path is counted by looking at the edges within the two subtrees rooted at the child of the original root. Since there are $n-1$ non-root nodes, we have
\[
P(T) = \sum_{x\in T} d(x,T) = \sum_{x\in T_L} d(x,T) + \sum_{x\in T_R} d(x,T) =\]\[ \sum_{x\in T_L} (d(x,T_L)+1) + \sum_{x\in T_R}(d(x,T_R)+1) = \sum_{x\in T_L}d(x,T_L) + \sum_{x\in T_R}d(x,T_R) + n-1 =\]\[ P(T_L) + P(T_R) +n-1
\]

\item
When we are randomly building our tree on n keys, we have $n$ possibilities for the first element that we add to the tree, the key that will belong to the eventual root. Suppose that it had order statistic $i+1$ for some $i$ in $\{0,\ldots  n-1\}$. Then, we have that all the smaller elements will be to the left and all the larger elements will be in the subree to the right. However, they will all be in random order relative to eachother, so, we will have $P(i) = E[P(T_L)]$ and $P(n-i-1) = E[P(T_R)]$. So, we have have the deisred ineqality by averaging over the order statistic of the first term put into the BST.

\item
\[
\frac{1}{n} \sum_{i=0}^{n-1} P(i) + P(n-i-1) + n-1 = \frac{1}{n}\left(\sum_{i=0}^{n-1}P(i) + \sum_{i=0}^{n-1}P(n-i-1) + \sum_{i=0}^{n-1}(n-1)\right)
\]

Then, we do the substitution $j = n-i-1$ and do the simple thing of summing a constant for the third sum to get

\[
=  \frac{1}{n}\left(\sum_{i=0}^{n-1}P(i) + \sum_{j=0}^{n-1}P(j) + n(n-1)\right) = \frac{2}{n} \sum_{i=0}^{n-1} P(i) + n-1
\]

\item
Our recurrence from the previous part is exactly the same as eq (7.6) which we showed in problem 7-3.e to have solution $\Theta(n\lg(n))$

\item
Let the first pivot selected be the first element added to the binary tree. Since every element is compared to the root, and every element is compared to the first pivot, we have what we want. Then, let the next pivot for the left (resp. right) subarrays be the first element that is less than (resp. greater than) the root. Then, we have that the two subtrees form the same partition of the remaining elements as the two subarrays left form. We can than continue to recurse in this way. Since if holds at the first element, and the problems have the same recursive structure, we have that it holds at every element.

\end{enumerate}



\end{document} 